sandbox.sources = eventlog
sandbox.channels = file_channel
sandbox.sinks = kafka

# Define / Configure source
sandbox.sources.eventlog.type = exec
sandbox.sources.eventlog.command = tail -F /var/log/eventlog-demo.log
sandbox.sources.eventlog.restart = true
sandbox.sources.eventlog.batchSize = 1000
#sandbox.sources.eventlog.type = seq

#Kafka Sink
sandbox.sinks.kafka.type = org.apache.flume.sink.kafka.KafkaSink
#sandbox.sinks.kafka.zk.connect = sandbox.hortonworks.com:2181
#sandbox.sinks.kafka.topic = all
sandbox.sinks.kafka.batchsize = 5
sandbox.sinks.kafka.brokerList = sandbox.hortonworks.com:6667
#sandbox.sinks.kafka.producer.type = async
sandbox.sinks.kafka.topic = sinkforflume
#sandbox.sinks.kafka.serializer.class = kafka.serializer.StringEncoder


# Use a channel which buffers events in memory
sandbox.channels.file_channel.type = file
sandbox.channels.file_channel.checkpointDir = /var/flume/checkpoint
sandbox.channels.file_channel.dataDirs = /var/flume/data

# Bind the source and sink to the channel
sandbox.sources.eventlog.channels = file_channel
sandbox.sinks.kafka.channel = file_channel
